{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: keras in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ort\\miniconda3\\envs\\basic_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.3-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] El proceso no tiene acceso al archivo porque está siendo utilizado por otro proceso: 'C:\\\\Users\\\\josel\\\\anaconda3\\\\envs\\\\taller_ds\\\\Lib\\\\site-packages\\\\matplotlib\\\\testing\\\\widgets.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.3-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.3 matplotlib-3.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ort\\AppData\\Local\\Temp\\ipykernel_27404\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ort\\miniconda3\\envs\\basic_env\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 150,\n",
    "                            activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.30))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 50,\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.30))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,750</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m117,750\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m7,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,810</span> (491.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,810\u001b[0m (491.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,810</span> (491.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m125,810\u001b[0m (491.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.0817 - val_accuracy: 0.9775 - val_loss: 0.0774\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0809 - val_accuracy: 0.9773 - val_loss: 0.0802\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.0785 - val_accuracy: 0.9798 - val_loss: 0.0757\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0748 - val_accuracy: 0.9788 - val_loss: 0.0782\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0704 - val_accuracy: 0.9798 - val_loss: 0.0746\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0688 - val_accuracy: 0.9791 - val_loss: 0.0770\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0645 - val_accuracy: 0.9787 - val_loss: 0.0744\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0636 - val_accuracy: 0.9798 - val_loss: 0.0769\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0618 - val_accuracy: 0.9794 - val_loss: 0.0763\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0549 - val_accuracy: 0.9807 - val_loss: 0.0747\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0568 - val_accuracy: 0.9815 - val_loss: 0.0713\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0518 - val_accuracy: 0.9813 - val_loss: 0.0707\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0511 - val_accuracy: 0.9800 - val_loss: 0.0772\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0504 - val_accuracy: 0.9807 - val_loss: 0.0730\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0493 - val_accuracy: 0.9808 - val_loss: 0.0780\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0505 - val_accuracy: 0.9803 - val_loss: 0.0778\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0489 - val_accuracy: 0.9814 - val_loss: 0.0798\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0510 - val_accuracy: 0.9795 - val_loss: 0.0802\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0498 - val_accuracy: 0.9807 - val_loss: 0.0812\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0445 - val_accuracy: 0.9815 - val_loss: 0.0781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 20,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.9879279e-13, 7.5335439e-11, 1.4094606e-10, ..., 1.0000000e+00,\n",
       "        5.2530727e-12, 1.7300904e-08],\n",
       "       [2.3214900e-11, 4.7749668e-04, 9.9951971e-01, ..., 7.1901431e-09,\n",
       "        2.0423688e-10, 4.0333597e-16],\n",
       "       [2.8353600e-10, 9.9999869e-01, 3.1750137e-08, ..., 1.0147963e-06,\n",
       "        3.4420495e-08, 5.2043900e-11],\n",
       "       ...,\n",
       "       [4.1583256e-17, 2.5648160e-15, 2.5386616e-14, ..., 9.0243472e-11,\n",
       "        1.2026504e-12, 2.9834331e-07],\n",
       "       [3.9586365e-16, 8.8912612e-17, 1.4945130e-18, ..., 4.7747148e-17,\n",
       "        1.0111183e-07, 2.2405423e-13],\n",
       "       [7.7334673e-11, 3.0106539e-16, 2.3292236e-12, ..., 6.5749847e-19,\n",
       "        1.8364265e-13, 1.2838906e-19]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 970,    1,    0,    1,    0,    1,    4,    1,    1,    1],\n",
       "       [   0, 1130,    2,    0,    0,    1,    2,    0,    0,    0],\n",
       "       [   2,    2, 1013,    3,    2,    0,    2,    6,    2,    0],\n",
       "       [   0,    0,    3,  995,    0,    3,    0,    4,    5,    0],\n",
       "       [   1,    0,    1,    0,  963,    0,    6,    3,    0,    8],\n",
       "       [   2,    1,    0,   12,    1,  866,    3,    0,    4,    3],\n",
       "       [   1,    2,    0,    1,    6,    3,  944,    0,    1,    0],\n",
       "       [   0,    8,    7,    5,    0,    0,    0, 1002,    2,    4],\n",
       "       [   3,    0,    2,    5,    5,    6,    1,    4,  945,    3],\n",
       "       [   3,    3,    0,    5,   13,    1,    0,    8,    2,  974]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9763 - loss: 0.0870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07475820928812027, 0.9801999926567078]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0824 - accuracy: 0.9774 - val_loss: 0.1075 - val_accuracy: 0.9697\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0795 - accuracy: 0.9786 - val_loss: 0.1035 - val_accuracy: 0.9714\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0767 - accuracy: 0.9796 - val_loss: 0.1019 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0738 - accuracy: 0.9805 - val_loss: 0.1002 - val_accuracy: 0.9721\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0711 - accuracy: 0.9812 - val_loss: 0.1050 - val_accuracy: 0.9709\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.0689 - accuracy: 0.9816 - val_loss: 0.0974 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0664 - accuracy: 0.9825 - val_loss: 0.0976 - val_accuracy: 0.9729\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0642 - accuracy: 0.9827 - val_loss: 0.0962 - val_accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0620 - accuracy: 0.9839 - val_loss: 0.0940 - val_accuracy: 0.9735\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0601 - accuracy: 0.9844 - val_loss: 0.0923 - val_accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7c796b8b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2606432437896729,\n",
       "  0.5073379874229431,\n",
       "  0.3963316082954407,\n",
       "  0.35093870759010315,\n",
       "  0.32315966486930847,\n",
       "  0.30234017968177795,\n",
       "  0.2859199047088623,\n",
       "  0.27146896719932556,\n",
       "  0.25876107811927795,\n",
       "  0.2474210113286972,\n",
       "  0.23700228333473206,\n",
       "  0.22742919623851776,\n",
       "  0.2186262160539627,\n",
       "  0.2104661762714386,\n",
       "  0.20308594405651093,\n",
       "  0.19585661590099335,\n",
       "  0.18922550976276398,\n",
       "  0.18290522694587708,\n",
       "  0.17689797282218933,\n",
       "  0.171352818608284,\n",
       "  0.16615021228790283,\n",
       "  0.16110429167747498,\n",
       "  0.15645083785057068,\n",
       "  0.15189804136753082,\n",
       "  0.14749477803707123,\n",
       "  0.14359557628631592,\n",
       "  0.13974981009960175,\n",
       "  0.13580283522605896,\n",
       "  0.13239270448684692,\n",
       "  0.12896263599395752,\n",
       "  0.12570436298847198,\n",
       "  0.1226966604590416,\n",
       "  0.1198044940829277,\n",
       "  0.1169242113828659,\n",
       "  0.11425230652093887,\n",
       "  0.11159147322177887,\n",
       "  0.1089780256152153,\n",
       "  0.10655452311038971,\n",
       "  0.1041840985417366,\n",
       "  0.10169029235839844,\n",
       "  0.09966576844453812,\n",
       "  0.09765546023845673,\n",
       "  0.09557442367076874,\n",
       "  0.09369782358407974,\n",
       "  0.09179524332284927,\n",
       "  0.08979883790016174,\n",
       "  0.08807747066020966,\n",
       "  0.0864119902253151,\n",
       "  0.08458385616540909,\n",
       "  0.0830993577837944],\n",
       " 'accuracy': [0.7007799744606018,\n",
       "  0.8722400069236755,\n",
       "  0.8917199969291687,\n",
       "  0.9013400077819824,\n",
       "  0.9087600111961365,\n",
       "  0.9143000245094299,\n",
       "  0.9188399910926819,\n",
       "  0.9232400059700012,\n",
       "  0.9266999959945679,\n",
       "  0.9297800064086914,\n",
       "  0.9329599738121033,\n",
       "  0.935920000076294,\n",
       "  0.9380800127983093,\n",
       "  0.9401999711990356,\n",
       "  0.9420999884605408,\n",
       "  0.9445400238037109,\n",
       "  0.9466000199317932,\n",
       "  0.9484400153160095,\n",
       "  0.9502800107002258,\n",
       "  0.9514600038528442,\n",
       "  0.9530400037765503,\n",
       "  0.9542999863624573,\n",
       "  0.9564599990844727,\n",
       "  0.957319974899292,\n",
       "  0.9582399725914001,\n",
       "  0.9593999981880188,\n",
       "  0.9607599973678589,\n",
       "  0.9617199897766113,\n",
       "  0.9631800055503845,\n",
       "  0.9637399911880493,\n",
       "  0.9650200009346008,\n",
       "  0.9660999774932861,\n",
       "  0.9670400023460388,\n",
       "  0.9677799940109253,\n",
       "  0.9686200022697449,\n",
       "  0.9692000150680542,\n",
       "  0.9701399803161621,\n",
       "  0.971019983291626,\n",
       "  0.9718199968338013,\n",
       "  0.9722599983215332,\n",
       "  0.9727399945259094,\n",
       "  0.9731000065803528,\n",
       "  0.9739599823951721,\n",
       "  0.9741399884223938,\n",
       "  0.9744600057601929,\n",
       "  0.9758399724960327,\n",
       "  0.9761000275611877,\n",
       "  0.9763399958610535,\n",
       "  0.9773200154304504,\n",
       "  0.9776800274848938],\n",
       " 'val_loss': [0.5861364006996155,\n",
       "  0.3909766972064972,\n",
       "  0.33547455072402954,\n",
       "  0.3042752742767334,\n",
       "  0.2837596535682678,\n",
       "  0.27178752422332764,\n",
       "  0.2558499872684479,\n",
       "  0.2443085014820099,\n",
       "  0.2347480207681656,\n",
       "  0.2256091833114624,\n",
       "  0.21768884360790253,\n",
       "  0.21016007661819458,\n",
       "  0.20285756886005402,\n",
       "  0.196963369846344,\n",
       "  0.19079934060573578,\n",
       "  0.18416495621204376,\n",
       "  0.1795361191034317,\n",
       "  0.17553065717220306,\n",
       "  0.1705842912197113,\n",
       "  0.16614820063114166,\n",
       "  0.16296935081481934,\n",
       "  0.1584606021642685,\n",
       "  0.1555926352739334,\n",
       "  0.15230843424797058,\n",
       "  0.14970067143440247,\n",
       "  0.14770159125328064,\n",
       "  0.14339327812194824,\n",
       "  0.1414082944393158,\n",
       "  0.1388157159090042,\n",
       "  0.13566303253173828,\n",
       "  0.1353430598974228,\n",
       "  0.13245968520641327,\n",
       "  0.12885329127311707,\n",
       "  0.12735068798065186,\n",
       "  0.1259734183549881,\n",
       "  0.12479826807975769,\n",
       "  0.12260467559099197,\n",
       "  0.12076063454151154,\n",
       "  0.11951550096273422,\n",
       "  0.11745229363441467,\n",
       "  0.11782617121934891,\n",
       "  0.11604565382003784,\n",
       "  0.11454316228628159,\n",
       "  0.11304052919149399,\n",
       "  0.11078294366598129,\n",
       "  0.11040539294481277,\n",
       "  0.10907091945409775,\n",
       "  0.10787728428840637,\n",
       "  0.1087631955742836,\n",
       "  0.10635022073984146],\n",
       " 'val_accuracy': [0.8748999834060669,\n",
       "  0.8995000123977661,\n",
       "  0.9077000021934509,\n",
       "  0.9157999753952026,\n",
       "  0.9214000105857849,\n",
       "  0.9241999983787537,\n",
       "  0.9279000163078308,\n",
       "  0.9296000003814697,\n",
       "  0.9330000281333923,\n",
       "  0.9366999864578247,\n",
       "  0.9394999742507935,\n",
       "  0.9401999711990356,\n",
       "  0.9424999952316284,\n",
       "  0.946399986743927,\n",
       "  0.9463000297546387,\n",
       "  0.9492999911308289,\n",
       "  0.9505000114440918,\n",
       "  0.9520999789237976,\n",
       "  0.9532999992370605,\n",
       "  0.954200029373169,\n",
       "  0.9559999704360962,\n",
       "  0.9567000269889832,\n",
       "  0.9581999778747559,\n",
       "  0.9588000178337097,\n",
       "  0.9587000012397766,\n",
       "  0.9606999754905701,\n",
       "  0.9610000252723694,\n",
       "  0.9611999988555908,\n",
       "  0.9621000289916992,\n",
       "  0.9634000062942505,\n",
       "  0.9641000032424927,\n",
       "  0.9635000228881836,\n",
       "  0.9646000266075134,\n",
       "  0.9653000235557556,\n",
       "  0.965399980545044,\n",
       "  0.965499997138977,\n",
       "  0.9671000242233276,\n",
       "  0.9666000008583069,\n",
       "  0.9679999947547913,\n",
       "  0.9685999751091003,\n",
       "  0.9685999751091003,\n",
       "  0.9686999917030334,\n",
       "  0.968999981880188,\n",
       "  0.9688000082969666,\n",
       "  0.9692000150680542,\n",
       "  0.970300018787384,\n",
       "  0.9700999855995178,\n",
       "  0.9700000286102295,\n",
       "  0.9696999788284302,\n",
       "  0.9700999855995178]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.06225531920790672,\n",
       "  0.06138444319367409,\n",
       "  0.06027477979660034,\n",
       "  0.059108540415763855,\n",
       "  0.058218587189912796,\n",
       "  0.05721678584814072,\n",
       "  0.05623963847756386,\n",
       "  0.055387239903211594,\n",
       "  0.05441601574420929,\n",
       "  0.05352767929434776,\n",
       "  0.052592288702726364,\n",
       "  0.051786866039037704,\n",
       "  0.05093264952301979,\n",
       "  0.05003897473216057,\n",
       "  0.0492832325398922,\n",
       "  0.04847511276602745,\n",
       "  0.04775787517428398,\n",
       "  0.04693999141454697,\n",
       "  0.046214886009693146,\n",
       "  0.045556679368019104,\n",
       "  0.04481605067849159,\n",
       "  0.04405045881867409,\n",
       "  0.04339233413338661,\n",
       "  0.04278245195746422,\n",
       "  0.042025357484817505,\n",
       "  0.041410598903894424,\n",
       "  0.040810007601976395,\n",
       "  0.04007289931178093,\n",
       "  0.03942100703716278,\n",
       "  0.03892222046852112],\n",
       " 'accuracy': [0.9837200045585632,\n",
       "  0.9840800166130066,\n",
       "  0.983959972858429,\n",
       "  0.9847999811172485,\n",
       "  0.9847999811172485,\n",
       "  0.9850999712944031,\n",
       "  0.9853399991989136,\n",
       "  0.9857400059700012,\n",
       "  0.986020028591156,\n",
       "  0.9861599802970886,\n",
       "  0.9864799976348877,\n",
       "  0.9866200089454651,\n",
       "  0.9870399832725525,\n",
       "  0.987280011177063,\n",
       "  0.9876800179481506,\n",
       "  0.9876800179481506,\n",
       "  0.987779974937439,\n",
       "  0.9884399771690369,\n",
       "  0.9884399771690369,\n",
       "  0.9886199831962585,\n",
       "  0.9889600276947021,\n",
       "  0.9894400238990784,\n",
       "  0.9895399808883667,\n",
       "  0.9896399974822998,\n",
       "  0.9898200035095215,\n",
       "  0.989799976348877,\n",
       "  0.9901400208473206,\n",
       "  0.9903799891471863,\n",
       "  0.9907799959182739,\n",
       "  0.9908999800682068],\n",
       " 'val_loss': [0.09174215793609619,\n",
       "  0.09083504974842072,\n",
       "  0.09042980521917343,\n",
       "  0.0904356986284256,\n",
       "  0.0902385339140892,\n",
       "  0.08940856158733368,\n",
       "  0.08886448293924332,\n",
       "  0.08740954101085663,\n",
       "  0.08680478483438492,\n",
       "  0.0871112123131752,\n",
       "  0.08641093969345093,\n",
       "  0.08738430589437485,\n",
       "  0.08585700392723083,\n",
       "  0.0853617712855339,\n",
       "  0.08460068702697754,\n",
       "  0.08507869392633438,\n",
       "  0.08454790711402893,\n",
       "  0.08406270295381546,\n",
       "  0.08393722772598267,\n",
       "  0.08294570446014404,\n",
       "  0.0827503651380539,\n",
       "  0.08226973563432693,\n",
       "  0.08175982534885406,\n",
       "  0.08106722682714462,\n",
       "  0.08092717826366425,\n",
       "  0.08086879551410675,\n",
       "  0.0810677707195282,\n",
       "  0.07988576591014862,\n",
       "  0.07975463569164276,\n",
       "  0.0791693851351738],\n",
       " 'val_accuracy': [0.972000002861023,\n",
       "  0.9731000065803528,\n",
       "  0.9732999801635742,\n",
       "  0.9732999801635742,\n",
       "  0.9733999967575073,\n",
       "  0.9736999869346619,\n",
       "  0.9732000231742859,\n",
       "  0.9736999869346619,\n",
       "  0.9746999740600586,\n",
       "  0.9735999703407288,\n",
       "  0.974399983882904,\n",
       "  0.9745000004768372,\n",
       "  0.9745000004768372,\n",
       "  0.9743000268936157,\n",
       "  0.9753999710083008,\n",
       "  0.9753999710083008,\n",
       "  0.9750999808311462,\n",
       "  0.9746000170707703,\n",
       "  0.9758999943733215,\n",
       "  0.9751999974250793,\n",
       "  0.975600004196167,\n",
       "  0.9764000177383423,\n",
       "  0.9764000177383423,\n",
       "  0.9761999845504761,\n",
       "  0.9761999845504761,\n",
       "  0.9771999716758728,\n",
       "  0.9765999913215637,\n",
       "  0.9767000079154968,\n",
       "  0.9765999913215637,\n",
       "  0.9778000116348267]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.185969</td>\n",
       "      <td>0.71750</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.8669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.506999</td>\n",
       "      <td>0.87242</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.396309</td>\n",
       "      <td>0.89220</td>\n",
       "      <td>0.331955</td>\n",
       "      <td>0.9103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.349226</td>\n",
       "      <td>0.90234</td>\n",
       "      <td>0.302923</td>\n",
       "      <td>0.9146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320345</td>\n",
       "      <td>0.90868</td>\n",
       "      <td>0.281495</td>\n",
       "      <td>0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.298978</td>\n",
       "      <td>0.91518</td>\n",
       "      <td>0.264784</td>\n",
       "      <td>0.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282174</td>\n",
       "      <td>0.92004</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.267849</td>\n",
       "      <td>0.92370</td>\n",
       "      <td>0.243314</td>\n",
       "      <td>0.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.255327</td>\n",
       "      <td>0.92746</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>0.9346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.244182</td>\n",
       "      <td>0.93136</td>\n",
       "      <td>0.223619</td>\n",
       "      <td>0.9368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.233754</td>\n",
       "      <td>0.93400</td>\n",
       "      <td>0.215580</td>\n",
       "      <td>0.9388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.224449</td>\n",
       "      <td>0.93630</td>\n",
       "      <td>0.207505</td>\n",
       "      <td>0.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.215747</td>\n",
       "      <td>0.93936</td>\n",
       "      <td>0.200709</td>\n",
       "      <td>0.9448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.207385</td>\n",
       "      <td>0.94200</td>\n",
       "      <td>0.194908</td>\n",
       "      <td>0.9466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.200191</td>\n",
       "      <td>0.94334</td>\n",
       "      <td>0.188915</td>\n",
       "      <td>0.9487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.193045</td>\n",
       "      <td>0.94518</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.186604</td>\n",
       "      <td>0.94740</td>\n",
       "      <td>0.178367</td>\n",
       "      <td>0.9525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.180346</td>\n",
       "      <td>0.94894</td>\n",
       "      <td>0.174028</td>\n",
       "      <td>0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.174644</td>\n",
       "      <td>0.95074</td>\n",
       "      <td>0.169282</td>\n",
       "      <td>0.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.169052</td>\n",
       "      <td>0.95218</td>\n",
       "      <td>0.164997</td>\n",
       "      <td>0.9554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.163799</td>\n",
       "      <td>0.95346</td>\n",
       "      <td>0.163356</td>\n",
       "      <td>0.9566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.159052</td>\n",
       "      <td>0.95476</td>\n",
       "      <td>0.157657</td>\n",
       "      <td>0.9591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.154176</td>\n",
       "      <td>0.95624</td>\n",
       "      <td>0.153952</td>\n",
       "      <td>0.9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.149838</td>\n",
       "      <td>0.95696</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.145802</td>\n",
       "      <td>0.95896</td>\n",
       "      <td>0.147259</td>\n",
       "      <td>0.9622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.141705</td>\n",
       "      <td>0.96050</td>\n",
       "      <td>0.143970</td>\n",
       "      <td>0.9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.137746</td>\n",
       "      <td>0.96118</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.134283</td>\n",
       "      <td>0.96196</td>\n",
       "      <td>0.140346</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.130634</td>\n",
       "      <td>0.96346</td>\n",
       "      <td>0.137091</td>\n",
       "      <td>0.9627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.127332</td>\n",
       "      <td>0.96446</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.96502</td>\n",
       "      <td>0.132365</td>\n",
       "      <td>0.9639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.121233</td>\n",
       "      <td>0.96586</td>\n",
       "      <td>0.130351</td>\n",
       "      <td>0.9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.118140</td>\n",
       "      <td>0.96716</td>\n",
       "      <td>0.127932</td>\n",
       "      <td>0.9662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.115378</td>\n",
       "      <td>0.96792</td>\n",
       "      <td>0.126108</td>\n",
       "      <td>0.9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.112639</td>\n",
       "      <td>0.96874</td>\n",
       "      <td>0.126224</td>\n",
       "      <td>0.9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.110172</td>\n",
       "      <td>0.96936</td>\n",
       "      <td>0.122289</td>\n",
       "      <td>0.9672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.107440</td>\n",
       "      <td>0.97014</td>\n",
       "      <td>0.120402</td>\n",
       "      <td>0.9682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.105028</td>\n",
       "      <td>0.97044</td>\n",
       "      <td>0.118940</td>\n",
       "      <td>0.9676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.102745</td>\n",
       "      <td>0.97182</td>\n",
       "      <td>0.117135</td>\n",
       "      <td>0.9691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.100516</td>\n",
       "      <td>0.97208</td>\n",
       "      <td>0.115622</td>\n",
       "      <td>0.9693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.97276</td>\n",
       "      <td>0.113876</td>\n",
       "      <td>0.9702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.096169</td>\n",
       "      <td>0.97352</td>\n",
       "      <td>0.112662</td>\n",
       "      <td>0.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.094144</td>\n",
       "      <td>0.97382</td>\n",
       "      <td>0.114285</td>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.092273</td>\n",
       "      <td>0.97466</td>\n",
       "      <td>0.110988</td>\n",
       "      <td>0.9716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.090404</td>\n",
       "      <td>0.97508</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.088425</td>\n",
       "      <td>0.97558</td>\n",
       "      <td>0.108157</td>\n",
       "      <td>0.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.086674</td>\n",
       "      <td>0.97632</td>\n",
       "      <td>0.107465</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.084962</td>\n",
       "      <td>0.97706</td>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.083115</td>\n",
       "      <td>0.97736</td>\n",
       "      <td>0.106349</td>\n",
       "      <td>0.9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.081606</td>\n",
       "      <td>0.97776</td>\n",
       "      <td>0.103869</td>\n",
       "      <td>0.9725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.185969   0.71750  0.580700        0.8669\n",
       "1   0.506999   0.87242  0.390600        0.8978\n",
       "2   0.396309   0.89220  0.331955        0.9103\n",
       "3   0.349226   0.90234  0.302923        0.9146\n",
       "4   0.320345   0.90868  0.281495        0.9231\n",
       "5   0.298978   0.91518  0.264784        0.9266\n",
       "6   0.282174   0.92004  0.252360        0.9280\n",
       "7   0.267849   0.92370  0.243314        0.9307\n",
       "8   0.255327   0.92746  0.233507        0.9346\n",
       "9   0.244182   0.93136  0.223619        0.9368\n",
       "10  0.233754   0.93400  0.215580        0.9388\n",
       "11  0.224449   0.93630  0.207505        0.9414\n",
       "12  0.215747   0.93936  0.200709        0.9448\n",
       "13  0.207385   0.94200  0.194908        0.9466\n",
       "14  0.200191   0.94334  0.188915        0.9487\n",
       "15  0.193045   0.94518  0.183801        0.9518\n",
       "16  0.186604   0.94740  0.178367        0.9525\n",
       "17  0.180346   0.94894  0.174028        0.9530\n",
       "18  0.174644   0.95074  0.169282        0.9558\n",
       "19  0.169052   0.95218  0.164997        0.9554\n",
       "20  0.163799   0.95346  0.163356        0.9566\n",
       "21  0.159052   0.95476  0.157657        0.9591\n",
       "22  0.154176   0.95624  0.153952        0.9581\n",
       "23  0.149838   0.95696  0.150610        0.9600\n",
       "24  0.145802   0.95896  0.147259        0.9622\n",
       "25  0.141705   0.96050  0.143970        0.9614\n",
       "26  0.137746   0.96118  0.142595        0.9616\n",
       "27  0.134283   0.96196  0.140346        0.9628\n",
       "28  0.130634   0.96346  0.137091        0.9627\n",
       "29  0.127332   0.96446  0.134150        0.9642\n",
       "30  0.124169   0.96502  0.132365        0.9639\n",
       "31  0.121233   0.96586  0.130351        0.9648\n",
       "32  0.118140   0.96716  0.127932        0.9662\n",
       "33  0.115378   0.96792  0.126108        0.9664\n",
       "34  0.112639   0.96874  0.126224        0.9649\n",
       "35  0.110172   0.96936  0.122289        0.9672\n",
       "36  0.107440   0.97014  0.120402        0.9682\n",
       "37  0.105028   0.97044  0.118940        0.9676\n",
       "38  0.102745   0.97182  0.117135        0.9691\n",
       "39  0.100516   0.97208  0.115622        0.9693\n",
       "40  0.098266   0.97276  0.113876        0.9702\n",
       "41  0.096169   0.97352  0.112662        0.9700\n",
       "42  0.094144   0.97382  0.114285        0.9688\n",
       "43  0.092273   0.97466  0.110988        0.9716\n",
       "44  0.090404   0.97508  0.109247        0.9706\n",
       "45  0.088425   0.97558  0.108157        0.9715\n",
       "46  0.086674   0.97632  0.107465        0.9711\n",
       "47  0.084962   0.97706  0.106141        0.9718\n",
       "48  0.083115   0.97736  0.106349        0.9710\n",
       "49  0.081606   0.97776  0.103869        0.9725"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABOWUlEQVR4nO3deXxU5d3//9d1Zt8y2ROSsAQIq4AIiGAVRK1L3VuktnorrdpN7XbX27a29dva321rF7t4W21r0da1WlvrWhcQF1ARWWSRnZAQyL7PPtfvjzMZEkhIohMSJp+nj3mcdc5cc8XwznXOda6jtNYIIYQQYvAYg10AIYQQYriTMBZCCCEGmYSxEEIIMcgkjIUQQohBJmEshBBCDDIJYyGEEGKQ9RrGSqn7lVLVSqkPetiulFK/VUrtUEptUEqdlPpiCiGEEOmrLy3jZcC5R9l+HlCWeF0P3PPxiyWEEEIMH72GsdZ6JVB/lF0uBh7UptVAplJqRKoKKIQQQqS7VFwzLgb2dVquSKwTQgghRB9Yj+WHKaWuxzyVjcvlmjVy5MiUHTsej6OVwb6WODlOhc+uUnbs4SYej2MY0rcvFaQuU0fqMnWkLlOjv/W4bdu2Wq11XnfbUhHGlUDnVC1JrDuC1vo+4D6A2bNn6zVr1qTg400rVqxg1imnMu22//C98ydx/enjUnbs4WbFihUsXLhwsIuRFqQuU0fqMnWkLlOjv/WolNrb07ZU/Gn0NPBfiV7VpwBNWuuqFBy339x282+L9nBsMD5eCCGE+Eh6bRkrpR4BFgK5SqkK4EeADUBr/QfgOeB8YAfQDiwdqML2xmIoHFZDwlgIIcRxpdcw1lpf0ct2DXwtZSX6mDwOK+3h6GAXQwghhOizY9qB61hw2Sy0h6RlLIQQQ148DvFo4hWBeOzQciwCsXCnV6fl6OHrQ91v1zHzmDp+6JVc7rSt43M71sVj5rzNBYuXHZOqSLsw9jgscppaCJF+omGItEE01DVckiETPxQysUjXcIp3Xo5QcGADvLenh1ALdwqkxPGSIaYTgRU1yxELm9NoyHxvNAyxEDocAmKoZLgdFnQdgYvu9qvqxGrVj5titDYPp+PKLLY2UBYLypqYWgwwDFAGKIs5NSygLGhlEI9ZiEcN4tGOqQKrG8/ij/lz66O0C2OX3UqbnKYWQvRHPJ4IpEOBcqiFddi6WLRTuEUOzXcOvGTIhdCRMDrQTjxkhpRScRQaDG3OG6A4FHo6HEAHWom3txNvayPeHiAeCBIPx4lHFTqmzNCBZJZprTrNJwIplnjFIR5TndZBBlCZCDqlgI7QMxRKGSiLgbKBYVUYNoWyKQyrkZwHg2jISixoEA0oogGItseJtcWJtkWIh+Lmsa0WlM2GslowbBZU4mXYLWZgRuPJVzwSQ0dj6EgMHYma30cpsBgowywTFgvKSISqYUDM3FdHo4n3dB/u5nczUHb7oZfNho5G0G3txAMB0EfmhpGhmXjbx/2fq2/SLow9dgsBaRkLMfRpnQiuIDrYlmgpxVDxWOKUZeJUZaIVlVW/Dv1hEEIB4sF2dKAdHWxHBwPoUMAMr/aWRIC1o9sDxAMB4oEQ8VCIeCiaaJXF0bHOpyjj6HgcUBgWjWGLY1i1+eoyr9FxiIUMYmHDnIYMop2W4xEjcYbTDL54XEG8b807ZQEMhY7qwxqMrsTro1E2qxmIdlsihKwEQ2GcDoe5Qxx0R7prjY7HIBwhHgyiQ6HDf2iJVxwww8vw+7Hm5mIdkYMzNxdLbg6WzEyIxdGhIPFQGB0MosOh5Hw8FMSwWM3yOOwYdkdi3pFcp5RhliUWN6fRmPlzikXRMfPnpmy2Q9/N1vWFxQqxKPFwGB2JoMNhdDgxTSwrqxXD7cbweDA8HVNPp3Wej1zv/ZV2Yey2W2hojwx2MYQ4pnQsRqy5mXhTE7HGRmKdpvFgqMs/xkaiVZBsIVgMiEXQ0TBEzdadjkUS82Gz9RAMmK27gNmK0MGg2WILhtChIDpyKDSVjtL1OmDU/EcxFCMejhEPa+IRbU6jinjUQHcJLA2qU4tNaRTg0LA11rkZ1w8GGDazNaWUFZTV/IBES7DjfKiOxokHI+ho3/6gN1wuLH4flkw/lsxMbD4fhsuNcrkwHC6U02mGjcOBcjjN1lg8BomWnI5GzfqNRpPrlN1+RCB0nld2G8piMcusDJSRqCzD/B7KMA6Fms1mtiQP09f7Y3U8bv6sg0F0oOOPmyAA1twcLDk5GHZ7338OokdpGMZWAnKaWgwV8TjR+npi9fVE6+qJNdQnlhuI1dcTb283/9F0Osx/sO2OrvM2m9nia20h1txCrKWZeHOLGbzNzcRams3AbWk9+im6AaAsZqtRWTTK4NBpRQxAoZMhZwaE4XBiOGwYWTasTjuGy4nhcmC4XCiXAwxrokVoJL6KSpx+NU/BVjc0UDByFIbTZQab04VyujCcHpTLjXJ5Mbw+s4XjTrxcLgy3G9XPwNDhcKfTxOY01taGslixZGVhyczEkpWZ9kGkDAOVqEsxsNIwjC20yWlq0Qc6EiFaX0+0ppZYXS3R2lqitXVEa83lWGMjoMzrVBbLoetVVgvKsIDFME93tQeIB4PEgwF0IJhoOZotiPy2Vrb3kJGG24HhtJktpEg0ee2sJ8qqsdg0hj2OxWa+7LY4lgKNZWQciz2OxXHY1OtGeXxoixdtdaMNN9riQSsn2nCaU+UAqxUsdpTVChYbWO3m1GJFWWwopxvD60W5vRhuL8rlQdmciX0cYHOC3WsuD5AtK1Yw7RiNGqXsdix2u3m6VYhjIA3D2CrXjNNIPBAgWlNDtLqaaHU1kepqotU1RGtr0MGQGYbdvaIR6DgNGIuhY1HzmlNimWgUHQ53+5mGy4kl04vV60hcX4ya74/FzA4jHdewYnGURWNYNMoSx2KJYxhRlBHF8GlUlhmeFkcciyOG1RHH4jSD0uowO+4AZq9OuxfsXrTNbQan4SZuuNHKgeFxY/G4UHYnWDpCMjE1bODwgjMTXJngzEpMM8HpN6+bCSGGvLT7TTVbxlG01qj+9IsXAyoeCiVOq7YmT7nGm5vMa5tNTcSampPz8aYmoo0NRKtriDc3H3EsZbdjzcvDcLvMlpvVSN6tYNg0ymFeY1TKQGEx3wMoDeg4ihgqbvZktdqC5ssZw+KMY3Wap16PpBKB6Um8Mg7N29yJqavTvBtsbrbuKmfStJM67edObju0nyt5zbLzFVHLAPwchBBDU/qFscOC1hCKxnHa5J+zgRRraSFSVUX04EFzeuAgkQMHiB44YAZrawvxllbiLS1mB5+jUE4HFq8bi9eFxePEke3AM6YUq9eK1QNWVxybM4LVFsSgBRVugPadEGw0e8T2xOIwW452Lzh8YPd3XXb6wZEBzoyu8x1Tu+9Q0H6EP+4OBFYw6YSF/X6fEGJ4Sb8wTgRwWygqYdxPOhol1tKC5eBB2t97z+xoVFdPtL6u67SujuiBA8Tb2roeQCmsOVlYszOweOzYR7gwRjmwWDMwjDAG7VhoxdDNWFS7eU3THsewxzGO9qMy3Jh3RvrBkgHOHMguBVcWuLPNqSu703Ji3pkxoNcwhRAiVdIvjB2HntyUM8hlGQxaa3QgcMTtLbHGTvNNTcSam5K9cmPNTcSbmpPhmgsc/pwvw+vG6vdg8TpxZNrwFBdic0WxOgLYrE3YqMVqbUEZhz09UxngzgFPPnjywDPFnLqyDp2ytXs7zXsOvRx+CVQhxLCQfmFsN5tY6TokptaaWGMjkYpKIpWVRCorCFdUmMsVFUT27+/mRv1DlNOBxefF4nFiuG3Y3BacmW4MmwOLxY/FEiQaacDtCmNVTVjsUbOz0eEtV6sTfIXgGwHeMebUV2i+vAXmtCN0j9rsFUIIkXZh7Ek+0/j4uNdYRyKJkYPMV6ypmWhdbeJ0cC2xujqiHfO1dURrao44PWz4/diKi3CMH4/3tFOxuA0s1jAWox2LbsISr8USPoAlWIER2d99QVzZiZZrHtXtGXhHTTRbtB2nfZPzWea80/+RrqEKIYQ4UtqFsWuQW8Zaa2L19UT2VxE5UEW06gCRqkPzsZaWZPDq9vZeOzZZ/H4sOTlYc3JwTJqEZ/5cbFkubBkGdk8Em60ZS/ggNJZD0wfQehA637FjsUPmKMgfDVlzzPmMYvDkJsMXd06XU8GbV6wg/xjdzymEECINw/hQy/jYhHGsuZm2Vatpe+MN2t991zxNfNj9q8rhwFZYiHXECBwFBYdGB3K7k6MFKZcLw+XG4gCrPYzFaMVKA6p1PzTtg6Y90Pg6BOqhDvMF5n2mmSPBPxLKPmmGbeZoyBptznsLzWHyhBBCDFlpF8aHWsYDc5pax+MEN22i9fXXaXvjTQLr10MshuH14j75ZLxnLsJWOALbCDN8bSNGYMnK6nrPcywKjXuh5kOo/RBq1pvTHdshdNh9tTa3GbSZI6HoJPCXmGGbOcpcJ2ErhBDHvbQLY48jdaep46EQkX37CJeXE95bTvCDD2h7801zmESlcE6dSs511+I97TRc06ebTwo5XLgd9r0NFWtg/1qo3gJ1O8yn1XTwFkDuBJh+OWSPO9TSzRxlXqOVa7NCCJHW0i6M3TbzK7WF+t4y1lrT/u67BDdsILy33Azf8nKiBw50GXzfkpeLd8ECPJ/4BJ5T52PNzu56oHgcardB5RqofM8M4IObzOeUAmSUQOEJMP4syJsIuRMht8wcvlAIIcSwlXZh3HGaui/jU8eammj65z9pePQxwrt3A2DJzsY+ahSek+dgGzUK++gx2EePwj5yZNdB47WGxn1m6O5fC5VrYf86CLeY2x0ZUDQTPvENKJ4NxSeZt/sIIYQQh0m7MLZbDWwWddQnNwU2bqThkUdpfu45dDCIa8YMRtzxv/gWLcKSkdH9m0KtsP0lM3wr15oB3FZjbjNsZot3+uVQMhuKZ0FOmVzLFUII0SdpF8bQ/TON44EAzc8+S8MjjxLctAnlduO/6CKyrvgszsmTuz9QqAW2vQibnoIdL0M0CCjzFPP4s83WbtFJZhBbHQP/xYQQQqSlNA3jrs80Dmz8gH3XX0+soQFH2XgKfnAr/osuwuLzHfnm7gLYWwgnXQ2TzjdbvY5u3ieEEEJ8RGkbxh3XjAObNlH+xS9i8fko+e1vcM2e3f2jFbf9B9Y+YJ6KjoXM4R1nXQNTLoGRc+WUsxBCiAGTpmFspS0cJbh1K/u+8EUMr4dRDzyAvaT4yJ1bDsLz34HN/zIDePZSCWAhhBDHVJqGsQXv/r2UX/MrlMvF6O6CWGtY/wi88F2IBODMH8L8m+QJQUIIIY65tAzjkU1VLHniTpTPxegHlmEfObLrDg174ZlvwM5XYeQpcNHvIG/CoJRVCCGESLswDu3cyRWP/YywMhj1wDLso0cf2hiPw7t/hJf/nzmq1fm/gNlflNPRQgghBlVahXFo1272XnMNKMXPzrqRf5aWHtpYsw2evhH2rYZxZ8KFd5nDTQohhBCDLG3C2HKwmvIf/BDimte+dBu7Kjv1mG6vhz8uMh9yf8kfYMZnZbxnIYQQQ0ZahHG4vJysX/8arRSjHlhGZFec9t27Du1QudYcpvKqf8K4MwatnEIIIUR30uJiaWD9BlQsyqhlf8E5YQIeu4VoXBOOxs0dqt43p8UnDV4hhRBCiB6kRcvYf+EFrLNamDpxIgAuu/m12sNR7FY7VK2H7LHg9A9mMYUQQohupUXLGEC7XMl5j/2wZxpXrYcRMwajWEIIIUSv0iaMO3Mlwzhqdt5qLJcwFkIIMWSlZRh7kqepY2arGGDEiYNXICGEEOIo0jKM3YmWcVsoBlXrzJXSMhZCCDFEpWcYO8yWcSASNVvG/lHgzh7kUgkhhBDdS88w7tyBq2o9FEmrWAghxNCV1mEcaW2E+l1yiloIIcSQlqZhbJ6mdtV9YK6QzltCCCGGsDQNY7Nl7G3YbK6QlrEQQoghLC3D2GE1MBRkN28GXxF48we7SEIIIUSP0jKMlVJ47FbyWrdC0YmDXRwhhBDiqNIyjAGybWFygjLylhBCiKEvbcN4urUcAy1hLIQQYsjrUxgrpc5VSn2olNqhlLqlm+2jlFLLlVLvK6U2KKXOT31R+2eq2mPOSE9qIYQQQ1yvYayUsgB3A+cBU4ArlFJTDtvtVuBxrfVM4LPA/6W6oP01Ue+i0cgCX+FgF0UIIYQ4qr60jE8Gdmitd2mtw8CjwMWH7aOBjMS8H9ifuiJ+NONjO9hhHQdKDXZRhBBCiKNSWuuj76DUZ4BztdbXJpavAuZqrW/otM8I4D9AFuABztJav9fNsa4HrgcoKCiY9eijj6bqe9Da2orX6wXAiIU49fUlPKguoXTBNSn7jOGic12Kj0fqMnWkLlNH6jI1+luPZ5xxxnta69ndbbOmqExXAMu01r9USs0D/qqUOkFrHe+8k9b6PuA+gNmzZ+uFCxem6ONhxYoVJI9XsQZe12yzTmBpCj9juOhSl+JjkbpMHanL1JG6TI1U1mNfTlNXAiM7LZck1nX2ReBxAK31KsAJ5KaigB/J/vcBWB8dPWhFEEIIIfqqL2H8LlCmlCpVStkxO2g9fdg+5cCZAEqpyZhhXJPKgvZL1XrarX52RrIGrQhCCCFEX/UaxlrrKHAD8CKwBbPX9Cal1I+VUhcldvs2cJ1Saj3wCHCN7u1i9ECqWk+NdxKhqCYWH7xiCCGEEH3Rp2vGWuvngOcOW/fDTvObgVNTW7SPKBqC6i00jLwSDkB7OIrPaRvsUgkhhBA9Sr8RuKo3QzxCc9ZUANrDsUEukBBCCHF06RfGVesBCOZKGAshhDg+pF8Y718HDj9xfykAbaHo4JZHCCGE6EX6hXHVehgxHY/TvBweiEjLWAghxNCWXmEci8DBTTBiBm67BZCWsRBCiKEvvcK4ZivEQlA0E7c90TKWa8ZCCCGGuFQNhzk0JDpvMWIGbpVoGUsYCyGEGOLSq2W8fx3YvZA9rlPLWE5TCyGEGNrSK4yr1kPhdDCMQ9eMpWUshBBiiEufMNYxOLARRswAwGUzw1juMxZCCDHUpU0Yu9srIRqAohMBMAyFy2ahXXpTCyGEGOLSJox9LTvNmUTLGMDjsNAu9xkLIYQY4tImjL2tO8Hqgpyy5DqXXVrGQgghhr60CWNfy04onAaWQ3dreexWuWYshBBiyEuPMI7H8bbu6nKKGhItYwljIYQQQ1x6hHH9Lqyx4BFhbLaM5TS1EEKIoS09wrhqnTlN9KTuIC1jIYQQx4P0COPsUiqKPwV5k7qs9kgYCyGEOA6kRxgXz2JH2fVgsXVZ7ZLT1EIIIY4D6RHGPZCWsRBCiONBWoexOxHG8bge7KIIIYQQPUrvMHaY9xwHo9I6FkIIMXSldxh3PLkpJGEshBBi6ErzMO54prGEsRBCiKErzcM48RjFiPSoFkIIMXQNizCW09RCCCGGsjQPYzlNLYQQYuhL8zBOtIxl4A8hhBBD2LAIY2kZCyGEGMrSOow9ifuMpWUshBBiKEvrMHZJy1gIIcRxIK3D2G2T3tRCCCGGvrQOY6vFwG415D5jIYQQQ1pahzEkntwkLWMhhBBDWNqHsdtulccoCiGEGNKGQRhbaJfe1EIIIYawYRLG0jIWQggxdA2DMLZKy1gIIcSQNgzCWFrGQgghhra0D2OXhLEQQoghLu3D2COnqYUQQgxxaR/GLrnPWAghxBCX9mHscVhoj8TQWg92UYQQQohuWQe7AAPNbbcSi2tC0TjOxFjVQgiRTiKRCBUVFQSDwT7t7/f72bJlywCXKv31VI9Op5OSkhJsNlufjzUMwvjQk5skjIUQ6aiiogKfz8eYMWNQSvW6f0tLCz6f7xiULL11V49aa+rq6qioqKC0tLTPx+rTaWql1LlKqQ+VUjuUUrf0sM/lSqnNSqlNSqmH+1yCAdYRxvJMYyFEugoGg+Tk5PQpiMXAUkqRk5PT57MUHXptGSulLMDdwNlABfCuUupprfXmTvuUAd8FTtVaNyil8vtVigHktptfUZ5pLIRIZxLEQ8dH+Vn0pWV8MrBDa71Lax0GHgUuPmyf64C7tdYNAFrr6n6XZIAcahlLGAshhBia+hLGxcC+TssViXWdTQAmKKXeVEqtVkqdm6oCflwdLWO511gIIQaO1+sd7CIc11LVgcsKlAELgRJgpVJqmta6sfNOSqnrgesBCgoKWLFiRYo+HlpbW7s93q4ms0X89nvrCO9L+/5qKdFTXYr+k7pMHanLnvn9flpaWvq8fywW69f+fTUQxxzKjlaPwWCwX/+/9iWdKoGRnZZLEus6qwDe1lpHgN1KqW2Y4fxu55201vcB9wHMnj1bL1y4sM8F7c2KFSvo7ngl1S2waiXjJk5h4YyilH1eOuupLkX/SV2mjtRlz7Zs2dKv3tED1Zva5/Ohtebmm2/m+eefRynFrbfeypIlS6iqqmLJkiU0NzcTjUa55557mD9/Pl/84hdZs2YNSim+8IUv8M1vfjPl5RooR6tHp9PJzJkz+3ysvoTxu0CZUqoUM4Q/C3zusH3+CVwB/EUplYt52npXn0sxgFwdp6lDcppaCJH+/t+/N7F5f/NR94nFYlgsfb/Vc0pRBj+6cGqf9v3HP/7BunXrWL9+PbW1tcyZM4fTTz+dhx9+mHPOOYfvf//7xGIx2tvbWbduHZWVlXzwwQcANDY29rlM6abXa8Za6yhwA/AisAV4XGu9SSn1Y6XURYndXgTqlFKbgeXAd7TWdQNV6P7wJDpwycMihBBi4L3xxhtcccUVWCwWCgoKWLBgAe+++y5z5szhL3/5C7fddhsbN27E5/MxduxYdu3axY033sgLL7xARkbGYBd/0PTpIqrW+jngucPW/bDTvAa+lXgdc6+Uv8LP9/+c2eHZeO1dOxG4kmEsLWMhRPrrSwt2MAb9OP3001m5ciXPPvss11xzDd/61rf4r//6L9avX8+LL77IH/7wBx5//HHuv//+Y1quoSJtxqbeH9nP7qbdR6y3WwyshpKWsRBCHAOnnXYajz32GLFYjJqaGlauXMnJJ5/M3r17KSgo4LrrruPaa69l7dq11NbWEo/H+fSnP83tt9/O2rVrB7v4gyYtuheP9Y8FYFfTLqblTeuyTSklzzQWQohj5NJLL2XVqlXMmDEDpRQ///nPKSws5IEHHuDOO+/EZrPh9Xp58MEHqaysZOnSpcTjcQD+93//d5BLP3jSIoxH+kZiwcKupu77jMkzjYUQYmC1trYCZgPozjvv5M477+yy/eqrr+bqq68+4n3DuTXcWVqcprYaVvJt+T2GsdtukRG4hBBCDFlpEcYABbaCbq8ZA7gdFhmbWgghxJCVNmFcaCtkX8s+wrHwEdvcNittcp+xEEKIISptwrjAVkBcx9nbvPeIbW6HhUBEWsZCCCGGprQJ40JbIUC3143ddou0jIUQQgxZaRPG+dZ8FIpdjd2FsVWuGQshhBiy0iaM7YadIm9Rzy1jCWMhhBBDVNqEMZiDf3QfxtIyFkKIdBCNpuclx7QL4z1Ne4jFuwav224hHIsTicUHqWRCCJH+LrnkEmbNmsXUqVO57777AHjhhRc46aSTmDFjBmeeeSZgDhCydOlSpk2bxvTp03nyyScB8HoPPVvgiSee4JprrgHgmmuu4ctf/jJz587l5ptv5p133mHevHnMnDmT+fPn8+GHHwLm06j++7//mxNOOIHp06fzu9/9jldffZVLLrkkedyXXnqJSy+99BjURv+kxQhcHcZmjiUcD7O/dT8jMw49gtnd6clNflda/f0hhBBdPX8LHNh41F1csShY+vHPf+E0OO+OXne7//77yc7OJhAIMGfOHC6++GKuu+46Vq5cSWlpKfX19QD85Cc/we/3s3GjWc6GhoZej11RUcFbb72FxWKhubmZ119/HavVyssvv8z3vvc9nnzySe677z727NnDunXrsFqt1NfXk5WVxVe/+lVqamrIy8vjL3/5C1/4whf6/t2PkfQK405jVHcNY/NrBsIx/C7boJRNCCHS3W9/+1ueeuopAPbt28d9993H6aefTmlpKQDZ2dkAvPzyyzz66KPJ92VlZfV67MWLFyefwdzU1MTVV1/N9u3bUUoRiUSSx/3yl7+M1Wrt8nlXXXUVf/vb31i6dCmrVq3iwQcfTNE3Tp20CuNSv/kD39W0iwUjFyTXexzmD7BNxqcWQqS7PrRgAwPwCMUVK1bw8ssvs2rVKtxuNwsXLuTEE09k69atfT6GUio5HwwGu2zzeDzJ+R/84AecccYZPPXUU+zZs4eFCxce9bhLly7lwgsvxOl0snjx4mRYDyVpdc7W7/CT48w5ohOXy2aGsXTiEkKIgdHU1ERWVhZut5utW7eyevVqgsEgK1euZPduc6jijtPUZ599NnfffXfyvR2nqQsKCtiyZQvxeDzZwu7ps4qLiwFYtmxZcv3ZZ5/Nvffem+zk1fF5RUVFFBUVcfvtt7N06dLUfekUSqswBvO68eFh7HGYfwXJwB9CCDEwzj33XKLRKJMnT+aWW27hlFNOIS8vj/vuu4/LLruMGTNmsGTJEgBuvfVWGhoaOOGEE5gxYwbLly8H4I477uCCCy5g/vz5jBgxosfPuvnmm/nud7/LzJkzu/Suvvbaaxk1ahTTp09nxowZPPzww8ltn//85xk5ciSTJ08eoBr4eIZeW/1jGusfy3O7nkNrnTzl4erowCVDYgohxIBwOBw8//zz3W4777zzuix7vV4eeOCBI/b7zGc+w2c+85kj1ndu/QLMmzePbdu2JZdvv/12AKxWK7/61a/41a9+dcQx3njjDa677rpev8dgSbuWcam/lJZIC7WB2uQ6T6IDV3tIwlgIIYabWbNmsWHDBq688srBLkqP0rJlDGYnrjx3HnDo1ibpwCWEEMPPe++9N9hF6FXatYw7h3GHPJ8Dh9VgS1XzYBVLCCGE6FHahXG+Ox+PzdPlgRFOm4W5Y3NYua1mEEsmhBBCdC/twlgpxVj/WHY37e6y/vSyXHbWtFHZGBikkgkhhBDdS7swBrMT1+G3N50+wbx+/Lq0joUQQgwxaRnGY/1jqQnU0BJuSa4ry/dSmOHk9e21R3mnEEIIceylbRhD105cSilOK8vljR21xOJ6sIomhBCCrk9oOtyePXs44YQTjmFpBl96hnFmIowbjzxV3RSIsKGicRBKJYQQQnQv7e4zBij2FmMzbEd04jp1fC5Kwcpttcwc1ftTQoQQ4njzs3d+xtb6oz+cIRaLJZ+A1BeTsifxPyf/z1H3ueWWWxg5ciRf+9rXALjtttuwWq0sX76choYGIpEIt99+OxdffHGfPxfMB0Z85StfYc2aNckRts444ww2bdrE0qVLCYfDxONxnnzySYqKirj88supqKggFovxgx/8IDkE51CXli1jq2FldMboIzpxZXvsTCv28/p26cQlhBCptGTJEh5//PHk8uOPP87VV1/NU089xdq1a1m+fDnf/va30bp/lwnvvvtulFJs3LiRRx55hKuvvppgMMgf/vAHvv71r7Nu3TrWrFlDSUkJL7zwAkVFRaxfv54PPviAc889N9Vfc8CkZcsYzOvGW+q3HLH+9LI87nltJ83BCBlOebaxECK99NaCBWgZgEcozpw5k+rqavbv309NTQ1ZWVkUFhbyzW9+k5UrV2IYBpWVlRw8eJDCwsI+H/eNN97gxhtvBGDSpEmMHj2abdu2MW/ePH76059SUVHBZZddRllZGdOmTePb3/42//M//8MFF1zAaaedltLvOJDSsmUM5nXjytZKQrFQl/WnleUSi2ve2lE3SCUTQoj0tHjxYp544gkee+wxlixZwkMPPURNTQ3vvfce69ato6Cg4IjnFH9Un/vc53j66adxuVycf/75vPrqq0yYMIG1a9cybdo0br31Vn784x+n5LOOhfQNY/9Y4jrOnqY9XdafNDoLj90ip6qFECLFlixZwqOPPsoTTzzB4sWLaWpqIj8/H5vNxvLly9m7d2+/j3naaafx0EMPAbBt2zbKy8uZOHEiu3btYuzYsdx0001cfPHFbNiwgf379+N2u7nyyiv5zne+w9q1a1P9FQdMWp+mBtjdtJuJ2ROT620Wg3njclm5vabLYxaFEEJ8PFOnTqWlpYXi4mJGjBjB5z//eS688EKmTZvG7NmzmTRpUr+P+dWvfpWvfOUrTJs2DavVyrJly3A4HDz++OP89a9/xWazUVhYyPe+9z3effddvvOd72AYBjabjXvuuWcAvuXASNswHp0xGoU6ohMXwIIJuby85SB769oZk+sZhNIJIUR62rhxY3I+NzeXVatWdbtfa2trj8cYM2YMH3zwAQBOp5O//OUvR+xzyy23cMstt3RZd84553DOOed8lGIPurQ9Te20Oin2FrOzcecR204rM4fGXCmnqoUQQgwBadsyBrMTV3ct4zG5HkZlu1m5rZb/mjfm2BdMCCEEGzdu5KqrruqyzuFw8Pbbbw9SiQZPeoexfyyr9q8iGo9iNbp+1dPKcvnn+5WEo3Hs1rQ9QSCEEEPWtGnTWLdu3WAXY0hI6xQa6x9LJB6hsrXyiG2nT8ijLRzj/fKGQSiZEEIIcUhah3GpvxQ4coxqgHnjcrAYSq4bCyGEGHRpHcbJB0Z0c904w2njpFGZ8khFIYQQgy6twzjDnkGuK7fbMAazV/XGyibq28LHuGRCCCHEIWkdxmBeNz786U0dTivLRWt4Y4e0joUQ4lg62vOMh6O0D+NSfym7mnZ1+6SQ6SWZ+F02Xt8m142FEGI4ikajg10EIM1vbQKzZdwWaaO6vZoCT0GXbRZD8YnxMjSmECJ9HPj//j9CW47+PONoLEZ9P55n7Jg8icLvfe+o+6Tyecatra1cfPHF3b7vwQcf5Be/+AVKKaZPn85f//pXDh48yJe//GV27TIvSd5zzz0UFRVxwQUXJEfy+sUvfkFrayu33XYbCxcu5MQTT+SNN97giiuuYMKECdx+++2Ew2FycnJ46KGHKCgooLW1lRtvvJE1a9aglOJHP/oRTU1NbNiwgbvuuguAP/7xj2zevJlf//rXfa7P7qR/GHfqxHV4GAOcPiGXZzdWsb26lQkFqX2kmBBCDBdLlizhG9/4RjKMH3/8cV588UVuuukmMjIyqK2t5ZRTTuGiiy7qteHjdDp56qmnjnjf5s2buf3223nrrbfIzc2lvr4egJtuuokFCxbw1FNPEYvFaG1tpaHh6LethsNh1qxZA0BDQwOrV69GKcWf/vQnfv7zn/PLX/6Sn/zkJ/j9/uQQnw0NDdhsNn76059y5513AvCXv/yFe++992PVHfQxjJVS5wK/ASzAn7TWd/Sw36eBJ4A5Wus1H7t0KdDxwIhdTbuYVzTviO3JoTG31UgYCyGOe721YGHoP89Ya833vve9I9736quvsnjxYnJzcwHIzs4G4NVXX+XBBx8EwGKx4Pf7ew3jJUuWJOcrKipYsmQJVVVVhMNhSkvN22JffvllHn300eR+WVlZACxatIhnnnmGUaNGEYlEmDZtWj9r60i9XjNWSlmAu4HzgCnAFUqpKd3s5wO+DgypcczyXHl4bd4eO3EVZboYn+9lpdziJIQQH0uqnmeciucgW61W4vF4cvnw93s8hx4SdOONN3LDDTewceNG7r333l4/69prr2XZsmX87W9/Y+nSpf0qV0/60oHrZGCH1nqX1joMPAp0d9L/J8DPgNQ8OTpFlFI9jlHd4bSyXN7eVUcwEjuGJRNCiPSSqucZ9/S+RYsW8fe//526ujqA5GnqM888M/m4xFgsRlNTEwUFBVRXV1NXV0coFOKZZ5456ucVFxcD8MADDyTXn3322dx9993J5Y7W9ty5c9m3bx9///vfueKKK/paPUfVlzAuBvZ1Wq5IrEtSSp0EjNRaP5uSUqXYWP/Ybkfh6nD6hDxC0Tjv7qk/hqUSQoj00t3zjNesWcO0adN48MEH+/w8457eN3XqVL7//e+zYMECZsyYwbe+9S0AfvOb37B8+XKmTZvGrFmz2Lx5MzabjR/+8IecfPLJnH322Uf97Ntuu43Fixcza9as5ClwgFtvvZWGhgZOOOEEZsyYwfLly5PbLr/8cubOnZs8df1xqe5u+emyg1KfAc7VWl+bWL4KmKu1viGxbACvAtdorfcopVYA/93dNWOl1PXA9QAFBQWzOp+L/7haW1t7vG/t5aaX+Vfjv/hZyc9wW9xHbA9FNV97pZ0zR1m5YrIjZWU6Xh2tLkX/SF2mjtRlz/x+P+PHj+/z/rFYDEs/elOLIy1evJivfOUrLFq0qNvtO3bsoKmpqcu6M8444z2t9ezu9u9LB65KYGSn5ZLEug4+4ARgRaKHXCHwtFLqosMDWWt9H3AfwOzZs/XChQv78PF9s2LFCno6ntqn+Ner/6JoWhEn5p/Y7T7nHFzLK1sP8v3LT2ZUzpGBPZwcrS5F/0hdpo7UZc+2bNnSrw5ZA9GBa7hobGzk5JNPZsaMGSxatKjHenQ6ncycObPPx+1LGL8LlCmlSjFD+LPA5zo2aq2bgGS7/mgt48HScXvTuup1PYbxrRdM5rVtNdzyjw08dO1cuedYCCEG2PH4POPMzEy2bdsGmH/UpEqvYay1jiqlbgBexLy16X6t9Sal1I+BNVrrp1NWmgFS4i1hVsEslm1axuUTL8dtO7LlO8Lv4rvnT+L7T33A39dUcPmckd0cSQghhqbjceCidH2ecW+Xf7vTp+EwtdbPaa0naK3Haa1/mlj3w+6CWGu9cCi1isHsUX3TzJuoC9bxyNZHetzvijmjmFuazU+e3czB5iHVKVwIIXrkdDqpq6v7SCEgUktrTV1dHU6ns1/vS/sRuDqcVHASpxafyv0f3M/lEy/HZz/yPL9hKO749HTOvWslP/jnB9x71azj7i9NIcTwU1JSQkVFBTU1fRtnPxgM9jssxJF6qken00lJSUm/jjVswhjgxpk38tlnPsuDmx/kayd+rdt9SnM9fPPsCdzx/Fae/+AA508bcYxLKYQQ/WOz2ZKjRvXFihUr+tW5SHQvlfWY9k9t6mxqzlTOGnUWD256kIZgz0OlXfuJUk4ozuCH/9pEY7s861gIIcTAGlZhDPC1E79GIBrg/g/u73Efq8XgZ5+eTkN7mNuf3XIMSyeEEGI4GnZhPD5rPJ8a+yke2foI1e3VPe43tcjPlxeM5Yn3KlgpzzsWQggxgIZdGAN8dcZXicVj3LfhvqPud+OiMsbmefjeUxtpCw2NB1ALIYRIP8MyjEdmjOTSskt5cvuTVLZW9rif02bhZ5+eTkVDgF/858NjWEIhhBDDybAMY4Drp1+PgcE96+456n5zxmTzX/NGs+ytPby39+jPxxRCCCE+imEbxoWeQpZMWsK/d/37qI9XBLj53EmMyHDynb+vp6YldIxKKIQQYrgYtmEM8MUTvojD4uD/1v3fUffzOqz8esmJVDUFWXLvKvY3Bo5RCYUQQgwHwzqMc1w5XDn5Sl7c8yJb67cedd+5Y3N48IsnU9MSYvEfVrG3ru0YlVIIIUS6G9ZhDHDNCdfgs/v4/fu/73XfOWOyefi6U2gPR1n8h1VsO5i6J3YIIYQYvoZ9GGfYM1g6dSmvVbzG+pr1ve4/rcTPY1+aB8CSe1exsaKpl3cIIYQQRzfswxjg85M/T7Yzm1vfuJWDbQd73X9CgY+/f3kebruVz/1xNe/uqT8GpRRCCJGuJIwBt83Nrxb+ippADVe/cDUVLRW9vmd0jocnvjKPvAwHV/35bV7fLqN0CSGE+GgkjBNmFczij2f/kZZwC1e/cDW7m3b3+p4RfhePf2kepblevrhsDS9uOnAMSiqEECLdSBh3Mi1vGvefcz/ReJRrXriGD+t7H3Ur1+vg0etOYWpxBl99aC2/f3U7sbg84FsIIUTfSRgfZmL2RJaduwybYeMLL36BjTUbe32P323jb1+cy/nTRvCL/2xjyb2r2FfffgxKK4QQIh1IGHej1F/KA+c9QIY9g2v/cy1rDqzp9T0eh5XfXTGT33z2RD482MK5d63k72v2obW0koUQQhydhHEPir3FLDt3GQWeAr7y8ld4s/LNPr3v4hOLeeEbp3NCsZ/vPLGBr/xtLQ1t4QEurRBCiOOZhPFRFHgKWHbuMsb4x3Djqzfyyt5X+vS+4kwXD193Ct89bxKvbD3IOXet5DV5JrIQQogeSBj3ItuZzZ/P+TOTcybzjRXf4Bfv/oJwrPeWrsVQfGnBOP75tVPJdNu4+v53uO3pTQTCsWNQaiGEEMcTCeM+yLBn8KdP/oklE5fwwOYHuOLZK9jesL1P751a5OfpGz7B0lPHsOytPZz5yxU8+V4FcelxLYQQIkHCuI9cVhe3nnIrd595N7WBWj77zGf56+a/EtfxXt/rtFn40YVTefxL88jzOfj239dzwe/e4I3ttceg5EIIIYY6CeN+Or3kdP5x0T+YXzSfn7/7c7700pf6NIQmwMml2Tz11VP5zWdPpDkY4co/v83V97/D1gPNA1xqIYQQQ5mE8UeQ48rht4t+yw/n/ZD1Neu57OnL+M+e//TpvYahuPjEYl759gK+f/5k3i9v4PzfvM7/PLGBg83BAS65EEKIoUjC+CNSSrF4wmIev+BxRvlG8e3Xvs333/g+DcGGPr3fYbVw3eljWXnzGXzh1FKeer+ShXeu4OcvbKW2NTTApRdCCDGUSBh/TGP8Y3jw/Af50vQv8cyuZzj/H+fzp41/IhjtWys3023n1gum8Mq3F3D2lALueW0np97xKj/81wcyipcQQgwTEsYpYDNs3DDzBv5x0T+YXTCb36z9DRc8dQH/2vEvYvG+3co0MtvNb6+YycvfWsAlJxbzyDvlLPzFCr752Do+PNAywN9ACCHEYJIwTqFxmeP43Zm/4/5z7ifPlcetb97KkmeW8FblW30/Rp6Xn31mOq/fvIil88fw4qYDnHPXSq594F3e2yvPTRZCiHQkYTwA5hTO4aFPPcSdp99Ja6SVL738Jb700pf69BSoDoV+J7deMIW3blnEN8+awHt7G/j0PatY/Ie3eGbDfsLR3m+pEkIIcXyQMB4ghjI4t/Rcnr7kaW6eczOb6jax+N+LuenVm3iz8s0+3Z8M5jXlr59Vxpu3LOJHF07hQHOQGx5+n/l3vMovXvyQysbAAH8TIYQQA8062AVId3aLnaumXMXF4y9m2QfLeHL7kyzft5wSbwmLJy7mkvGXkO3M7vU4bruVpaeWcvW8Mby2vYaHVu/l/1bs4P9W7GDRpHyuPGU0p5flYRjqGHwrIYQQqSRhfIxk2DO46aSb+PKML/NK+Ss89uFj/Pq9X/P793/PWaPPYsnEJZyUfxJKHT1MDUNxxsR8zpiYT0VDO4+8U85j7+7j5S3VjMp287m5o7jspGLyfc5j9M2EEEJ8XBLGx5jdYue80vM4r/Q8djbu5O/b/s7TO57m+d3PM84/jkvGX8LCkQsZ4x/T67FKstx855xJfP3MCby46QB/W72XO57fyp0vfshpZblcdlIJn5xSgNNmGfgvJoQQ4iOTMB5E4zLHccvJt3DTzJt4cc+LPP7h4/zyvV/yy/d+yeiM0ZxecjoLShZwUv5J2Cy2Ho9jtxpcOKOIC2cUsaO6lafer+CptZXc9Mj7eB1Wzp9WyKUzS5hbmi2nsYUQYgiSMB4C3DY3l5ZdyqVll1LZWsnKipW8VvEaj259lL9u/item5f5RfNZMHIBnyj+xFGvMY/P9/Kdcybx7bMn8vbuev6xtoJnN1Tx+JoKijNdXDKziEtnFjM+33cMv6EQQoijkTAeYoq9xVwx6QqumHQF7ZF2VletZmXFSlZWrOQ/e/+DoQxOyj+Js0afxZmjzqTQU9jtcQxDMW9cDvPG5fDji0/gP5sP8I+1ldyzYid3L9/JpEIfF84o4oLpIxid4znG31IIIURnEsZDmNvmZtGoRSwatYi4jrOlfgvLy5fzSvkr3PHOHdzxzh1My53GmaPO5OzRZzMqY1S3x3HZLVx8YjEXn1hMdUuQ5zZU8e8NVdz54ofc+eKHTC/xc+H0Ij41fQRFma5j/C2FEEJIGB8nDGUwNWcqU3OmcsPMG9jdtJtXyl/h5b0vc9fau7hr7V2UZZVx1qizOGv0WZRllnXbMzvf5+SaU0u55tRSKhsDPLthP/9eX8VPn9vCT5/bwuzRWUx0RRhX387IbPcgfFMhhBh+JIyPU6X+Uq6ddi3XTruW/a37k8H8h/V/4J719zA6YzRnjTqLs0efzZScKd0Gc3Gmi+tPH8f1p49jT20bz2zYz9Pr9/PQ3jAPbV3OpEIfn5xSwFlTCjihyC+dv4QQYoBIGKeBIm8RV025iqumXEVtoJZXy1/lpb0vsWzTMv78wZ8p8hRx1mgzmKfnTcdQRw68NibXww2LyrhhURmPPvsqzb7RvLy5mt8v38FvX91BQYaDMycXcPbkAuaNy5HbpYQQIoUkjNNMriuXyydezuUTL6cx2Mjyfct5ae9LPLz1YR7c/CD5rnxOKzmNU4pOYW7hXLKcWUcco9Bj8NlEi7m+LczyrdW8tPkg/3y/koffLsdttzB/XA4LJuazcEKenM4WQoiPScI4jWU6M5O3TLWEW3it4jVe3vsyL+55kSe3PwnApOxJzC2cyylFp3BS/km4bV2DNdtj59OzSvj0rBKCkRirdtXxypaDrPiwhpe3VAPm7VQLJ+SxcGI+c0qzcFil1SyEEP0hYTxM+Ow+Lhh7AReMvYBoPMqmuk28XfU2q6tW8/DWh3lg8wNYDSsz8mZQGCwkszqTE3JPwGoc+l/EabMkh+LUWrOzpo0VH1bz2rYaHly1lz+9sftQq3lCHqeV5TEmV26bEkKI3kgYD0MdoTsjbwbXT7+eQDTA+wffZ/WB1azev5rnmp7j2eefxWPzMKdgDqcUncIpI05hrH9ssiOYUorx+V7G53u59rSxtIejrNpZx/IPq7u0mkdluzmtLJfTyvKYPz6HDGfPI4kJIcRw1acwVkqdC/wGsAB/0lrfcdj2bwHXAlGgBviC1npvissqBojL6mJ+8XzmF8+HWfDsK89iG2djddVqVletZkXFCgDyXHmcMuIU5o6Yy8z8mYz0jUyGs9tu5czJBZw5uQCtNXvq2nl9ew0rt9Xyz/creejtciyGYubITE4ry+PU8TlMK/HLKW0hhKAPYayUsgB3A2cDFcC7SqmntdabO+32PjBba92ulPoK8HNgyUAUWAw8j8XDwjEL+eSYTwJQ2VppntLev5o397/Jv3f9G4BsZzbTc6czI99sZU/NmYrb5kYpRWmuh9JcD/81bwyRWJy1ext4fXstr2+v4a5XtvHrl80xtU8syWT2mCzmlGZz0qgs/C5pOQshhp++tIxPBnZorXcBKKUeBS4GkmGstV7eaf/VwJWpLKQYXMXeYi4ru4zLyi4jruPsaNzB+pr1rK9ez/qa9cmWs0VZmJA1gel505maM5XJOZMZ5x+HzWJj7tgc5o7N4b/PmUhDW5h39tTz7u563t3bwH0rd/F/K3aiFEwqzGDOmCxmj8lmzpgsRvhlRDAhRPpTWuuj76DUZ4BztdbXJpavAuZqrW/oYf/fAwe01rd3s+164HqAgoKCWY8++ujHLP4hra2teL3elB1vOOtvXbbF2tgT3sPu0G52h3azN7SXkA4BYMHCCPsISmwllNjNV5G9CJdxKGRDUc3OpjjbG2Jsa4ixozFOKGZuy3UpyrIMJmRamJBlYYRXYfTyzOehRP6/TB2py9SRukyN/tbjGWec8Z7WenZ321LagUspdSUwG1jQ3Xat9X3AfQCzZ8/WCxcuTNlnr1ixglQebzj7uHUZi8cobylna/3WLq/VDauT+4zOGM3k7MlMzpnMlJwpfD57Mn6HH4BoLM7mqmbW7Glgzd563tndwKr9Zrj7XTZmjzZbzjNHZTKt2I/HMXT7Icr/l6kjdZk6Upepkcp67Mu/YpXAyE7LJYl1XSilzgK+DyzQOtEsEsOSxbBQ6i+l1F/KeaXnAaC1piZQw9b6rWyp28KW+i1sqNnAC3teSL6v2FvMlJwpyZA+f+Z4lp56EgDl9e28s7ueNXsaeHdvPa9sNXtrGwrK8n3MGOlnxshMZpRkMrHQh81y5ChjQggxVPUljN8FypRSpZgh/Fngc513UErNBO7FPJ1dnfJSiuOeUop8dz757nxOLzk9ub4x2Mjm+s1sqdvC5rrNbKnfwkt7X0pu99q8jM0cy/jM8Yzzj+PieeP51nmTsepMNlQ2sa68kfUVjby0+SCPr6kAwGkzOKHIz/SSTKaX+Jle4mdMjkfG1hZCDFm9hrHWOqqUugF4EfPWpvu11puUUj8G1mitnwbuBLzA3xO3upRrrS8awHKLNJHpzGR+0XzmF81PrmsON/Nh/YfsbNzJjsYd7GzcyfLy5fwj9I/kPj67j7LMMsqyyjh//gS+nlmGSxez7WCU9fsaWbevkYff2cv9b8bN/Z1WphV3DejiTFe3D9AQQohjrU8X27TWzwHPHbbuh53mz0pxucQwlmHPYE7hHOYUzumyvi5Qx66mXexo3MGOhh1sb9zOs7ue5bHIY8l9ir3FlGWVsfCUCVzjK4VoLnWNPrZXxdlQ0cSf39hFJGZ2Wsz22JkyIoMpRRlMHuFjygg/Y/M8copbCHHMDd2eL0IcJseVQ44rp0tIa62paqtiW8M2tjdsT05fr3idmI4l9/M7/IweO5pLp5fgUoWEAlnUN2ZQWQ3L3qonHDVb0HarwcQCH1NGmAE9eUQGk4syZOQwIcSAkjAWxzWlFEXeIoq8RSwcuTC5PhQLUdFSQXlzOeUt5ext3kt5Sznrat7nQNsBNIlb+jKguCCPQtdI3KqIaDCXxqYsXvzQw2Nr3IDZSi7OdDF5RAZTOgJ6RAajst1yHVoIkRISxiItOSwOxmWOY1zmuCO2dQT1nuY97Gnaw+6m3exu3s2WxtdoibSYvxUlkGtxkGMvwkE+kVAOm5syWFHuJRbKRUcz8NhtTCj0MbHAx4QCHxMLzWmez3Hsv7AQ4rgmYSyGnZ6CWmtNXbCO3U272dNshvS+5n2Ut5RTHXqfsC+My2fua1E23CqP/VEPO6ut/LPSjo47Ie7AZXGT5/VTnJGFo10T2lLCzJIS8rwO6TAmhOiWhLEQCUopcl255Lpyj+g8Ftdxqturk6e9y1vKqWipoCnURGukleZQA82hFtqj7UR1iAPAgXbzvW+9cy/xN30YkWIyrWMY5RnPlNxJzBwxngkFGYzOkU5jQgx3EsZC9IGhDAo9hRR6Cjl5xMlH3Tcaj9IWaaM51MJjy5+lLTPOlrqt7GvbSWPsJRojL7ChCh6ptBEPFaAjWWRY8ynwjKDUX8LkvFHMLBrHtKJ83Hb5FRViOJDfdCFSzGpY8Tv8+B1+ZvsnsnDBwuS2cCzMrqZdrD+4mTVVH7CtYQc1gQO0xrawW0fZ3QivNgLbQcecWOI5eCw5ZDvyKPIWMiazmIm5JUwtGMWojBG4be5B+pZCiFSSMBbiGLJb7EzKnsSk7EksmXxZcn1cx6kP1rO3qYKNB/awpXYvexorqQ5U0RypY29wJ3sjbaxqAHYfOp5Fu3Fbcsiy51HoKWBkxgjKckoozSym0FNIgacAj81z7L+oEKJfJIyFGAIMZSSvV88qPLHbfQ62NLNufzmba8rZWV9JZcsBqtsP0hKoo1EdZE/rNt6pa+0S1gA25SLDlkeeK4+SjBGUZhZR6Cmg0FNIvjufPFceHpsHh0U6mAkxWCSMhThOFPgyOGfiCZwz8YQjtrWGouyrb2dXbSNbayrZ2VBJRXMV1YGDNIVrabc0Um2rZnPtdpS1BaWOfHSqwsBldeGxuXFZXbisLtw2N26rG5/dh9/hJ9ORSaYjs8t8piOTHFeOnDIX4mOQMBYiDXgd1uRgJJ9iVJdt8bjmYEuQvXXtlNe3s7euhe11VZQ3VXGg7QBtsQaUEQYjTEiFaLdFcTljOO1RbNYIhqWaKHsIxJppj7YeGjDl8DLYvOS78ylwF5hTT0FyvqMFnu3MxmJYjkWVCHFckTAWIs0ZhmKE38UIv4tTxuYk1k5Jbm8JRqhoCFBe386++nYqGgLsq2+nvK6dfQ3tBCPxTkeL43SEyM+Mk+WL4PdE8LhC2OytxC1NhHQ9zeE6djbtpDZQS1zHu5ZFGWQ5sshz5yVPy+e58shx5ZBhz8Br8+K1e/HZfXht5tRj82A15J8qkd7k/3Ahhjmf08bkETYmj8g4YpvWmtrWMPsbA1Q1BdjfGDSnTUGqGgNsrwlysDlI/LDGco7HzshMO3n+CH5fO05XCzZbG3FLM2EaaY82UBusZVv9NuqCdV3GEe+O2+rGru3kPZ2Hz+Yjw5FBhj3xSsz7HX6yHdlkOjPJcmSR5czCaXWmsqqEGDASxkKIHimlyPM5yPM5mDEys9t9orE4B1tCVDYEqGxsZ39jkIqGAJWNAfbVwurtdgKRTCATKAbAUJDnc1CY4WRchp0cfwyfJ4LPFcXtjGC3R7DZQkR0O63hVloiLWzfux23101zuJn9rfvZGt5Kc6iZ9mh7j+V3WV1kObKSAd3R6vbZfHjt3mTru6MlbigDjUZrnTwd33neZ/dR7C3G7/CnrpKFQMJYCPExWS0GxZkuijNdQPYR27XWNLZHONAc5EBTkKqmIAeaAhxoNud31wZYtTNISyja6V0KcOKxeyjwj6Qww4lun06pezQneB3kFzrI8zrIz3CQ5bGAEaA53ExjqJH6YD2NwUYaQg00BBu6rKtsraQl3EJrpJVQLPSRv7PP5qPYV0yx99CrxFdCgbsAv8OPz+7DbXVL73TRZxLGQogBpZQiy2Mny2Pv9lR4h7ZQlIPNQQ42hxLTIAc6pk1B9jXGWfvWHkLR+BHvdVgN8jMcFPicFGRkkZ9RSEGGk/EZDgqynORnOMnPcOBzWJMBGY6Fk8Hc0fqO6zgKhVKK5H+dArUp1ERlayUVLRVUtlayu2k3b1a+STAWPKJMhjKSLe8Me0ay9e2xecxe6ome6m6r+9C6xHyytW734rF6pNPbMCBhLIQYEjwOK2PzvIzN83a7fcWKFSxYsIDmYJSalhDVLUFqWkKJeTPAq5tDbDnQzGvbQrR2aWmb7FaDPK+DXJ+DPK+dPJ+DXK+DXK+HPF82uV4HOV47uV4HGU5rn1q2HQ8YqWipoLq9mpZwCy3hFprDzbRGWpPLLeEWylvKCUQDtEXaaI+0E46H+1Y3Nk8y2LsEeqcg99g8yeWOjnCHTx2Wj/9EMa3NU/bS6k8tCWMhxHFDKYXfZcPvsjE+v/vQ7tAailKdaGlXt5gt7NrWMDUtIWpbQ1Q0BFi3r4n6ttARHdDADO5cj53cZGDbyfE6yPHYyU609DvmczxZnJif2+/vE4lHaI+0E4gGaI+00xZpM1vqHa31RMu9I8w7trWEW8zb0qJmqLdH2onqI//4OJzNsOGz+yACWf80O7g5rc7kfeVOi7kc07FkWdoj7V2mbeE2APLceUfcxlbgLqDAU0CeK48MR4a06vtBwlgIkZa8Diveo7S0O8Timob2QyFd2xqitiVMbWuImtYQta1hDjQF+aCyifq2MNHukhtw2Sxkd4S3x2xd5/oS08Qrz2cn2+PA77JhMRQ2w5Ycx/zj0FoTjocPBWakzQzvcGvXcI+Y6/ZU7iEzM5NANEAgGqAh2EBVtIpgLEggGsCqrLht7mQrfKR3JF67F7fVjdfuRWtNTaCGg20H2dawjdcrXycQDXRbto73dGml27zJPwIcFgcOiwOn1YnD4uiyzmbYsBpWbIYNm8VmTjvWWWy4rYcGqLEZtuO6tS5hLIQY1iyGSoZlb7TWNAej1LeFO71C1LdFqG8LUdcaprYtTFVTkI2VTdS1hYl1E95KQabLlmxdZ7kPtbaz3Day3Oa6LI+NzMR8R4B3RymVDLAsZ1av32PFihUsXLiw1/36SmtNS6SFg20HOdh+kJr2mi4t+eQfBYnW/v7W/QRjQULRkDmNhY64J72/LMqSDOaOl1KKuI4ne8jHdTz5OXEdN3vbO83b4LKd2WQ6Msl2ZpvrHOa6sZljU1FFvZIwFkKIPup8mrw0t/cHcMTjmsZAJNHaNlvaDW1h6tsj5jTxKq9vZ92+xqO2vJUCv8sM6ky3zQxztz0R1jZzXSK4M91m0Ge6bLjtlgFvMSqlkvd9l2WV9fv9Wmsi8UiXgA7HwkTjUSLxCJF4xJyPRZLLoViIYDSYbN0HogHao+Yp/0AkQCBmttQNDJRSGMpIdsgzMEBBIBKgPlRPZW0ljcFGWiItXcrltXlZ9blVKamj3kgYCyHEADEMRXbiuvKEAl+v+2utaQ1FaWiL0NAepqE9TGN7Yr4tTENivikQoaY1xLaDrTS2h2kL9zxoit1qdApuc9reFGJVYAuZLrPF3RHuGYl5v8uG19G3DmypoJTCbrFjt9jBfkw+sluRWCR5S1xDqIFg9Mhe8gNFwlgIIYYIpRQ+pw2f08aonL4/eCMcjdMYSAR3IrQb28M0BszwbkyEe2N7hJ01rVQ3xVhdtYdwrOdTwxZDkeG0Js8EZCSmnZcznDZ8Tmti3orPaSPDZSXDacNpO/46btkstuRY6seahLEQQhzn7FaDfJ+TfF/fhv/suE0sGDFDvCkQobE9kpiay4de0eR8RUOApkCE5kCkx9PpyTJZjGQw+xJhnZEIa5/Tlgz6jE5Bn+HsCHorDuvxF+Yfh4SxEEIMQ0opXHYLLrv5EJH+0FoTiMRoCUZpDkRoDkZoTs6b05Zg1FzfaX5/Y4CWoBnu3Q3e0pnDaiTOElgPvRw2vMllGz6HOe9NLHsdh/b1Oqx47FaMHjq9DTUSxkIIIfpFKYXbbsVtt1KQ8dEexhGKxmju1OruCO6OlndzMEpLIuRbE/PVzeZgLi3BaLeDuhxZTvA5zNPoHa3xzqfSvQ4rHocVj8OCx95p3mFNbjOHeR14EsZCCCGOOYfVQp7PQp7vo40KFotr2sIdQR2lNWS2wDuCuiV4aDnZYg9GqGwMsKXKDP+2ULTbAV86+JxWNt52zkf8hv0jYSyEEOK4Y3YwM68zf1Raa4KROG3hKG0hM8TbQrHkcnf3iA8UCWMhhBDD0qHr5pY+DfoykIxB/XQhhBBCSBgLIYQQg03CWAghhBhkEsZCCCHEIJMwFkIIIQaZhLEQQggxyCSMhRBCiEEmYSyEEEIMMgljIYQQYpBJGAshhBCDTMJYCCGEGGQSxkIIIcQgkzAWQgghBpmEsRBCCDHIJIyFEEKIQSZhLIQQQgyyPoWxUupcpdSHSqkdSqlbutnuUEo9ltj+tlJqTMpLKoQQQqSpXsNYKWUB7gbOA6YAVyilphy22xeBBq31eODXwM9SXVAhhBAiXfWlZXwysENrvUtrHQYeBS4+bJ+LgQcS808AZyqlVOqKKYQQQqSvvoRxMbCv03JFYl23+2ito0ATkJOKAgohhBDpznosP0wpdT1wfWKxVSn1YQoPnwvUpvB4w5nUZepIXaaO1GXqSF2mRn/rcXRPG/oSxpXAyE7LJYl13e1ToZSyAn6g7vADaa3vA+7rw2f2m1JqjdZ69kAce7iRukwdqcvUkbpMHanL1EhlPfblNPW7QJlSqlQpZQc+Czx92D5PA1cn5j8DvKq11qkooBBCCJHuem0Za62jSqkbgBcBC3C/1nqTUurHwBqt9dPAn4G/KqV2APWYgS2EEEKIPujTNWOt9XPAc4et+2Gn+SCwOLVF67cBOf09TEldpo7UZepIXaaO1GVqpKwelZxNFkIIIQaXDIcphBBCDLK0COPehusUPVNK3a+UqlZKfdBpXbZS6iWl1PbENGswy3g8UEqNVEotV0ptVkptUkp9PbFe6rKflFJOpdQ7Sqn1ibr8f4n1pYnhdnckht+1D3ZZjxdKKYtS6n2l1DOJZanLj0AptUcptVEptU4ptSaxLiW/48d9GPdxuE7Rs2XAuYetuwV4RWtdBrySWBZHFwW+rbWeApwCfC3x/6HUZf+FgEVa6xnAicC5SqlTMIfZ/XVi2N0GzGF4Rd98HdjSaVnq8qM7Q2t9YqdbmlLyO37chzF9G65T9EBrvRKzB3xnnYc3fQC45FiW6Xikta7SWq9NzLdg/sNXjNRlv2lTa2LRlnhpYBHmcLsgddlnSqkS4FPAnxLLCqnLVErJ73g6hHFfhusU/VOgta5KzB8ACgazMMebxFPLZgJvI3X5kSROq64DqoGXgJ1AY2K4XZDf8/64C7gZiCeWc5C6/Kg08B+l1HuJESUhRb/jx3Q4THH80VprpZR0ue8jpZQXeBL4hta6ufPzUqQu+05rHQNOVEplAk8Bkwa3RMcnpdQFQLXW+j2l1MJBLk46+ITWulIplQ+8pJTa2nnjx/kdT4eWcV+G6xT9c1ApNQIgMa0e5PIcF5RSNswgfkhr/Y/EaqnLj0Fr3QgsB+YBmYnhdkF+z/vqVOAipdQezEt4i4DfIHX5kWitKxPTasw/Ek8mRb/j6RDGfRmuU/RP5+FNrwb+NYhlOS4krsP9Gdiitf5Vp01Sl/2klMpLtIhRSrmAszGvwS/HHG4XpC77RGv9Xa11idZ6DOa/ja9qrT+P1GW/KaU8SilfxzzwSeADUvQ7nhaDfiilzse8LtIxXOdPB7dExw+l1CPAQsynjxwEfgT8E3gcGAXsBS7XWh/eyUt0opT6BPA6sJFD1+a+h3ndWOqyH5RS0zE7wlgwGwyPa61/rJQai9m6ywbeB67UWocGr6THl8Rp6v/WWl8gddl/iTp7KrFoBR7WWv9UKZVDCn7H0yKMhRBCiONZOpymFkIIIY5rEsZCCCHEIJMwFkIIIQaZhLEQQggxyCSMhRBCiEEmYSyEEEIMMgljIYQQYpBJGAshhBCD7P8HEpgOo2XbJ8UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0884 - accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08835859596729279, 0.9739000201225281]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.1-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.8.1-cp39-cp39-win_amd64.whl (36.9 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\josel\\anaconda3\\envs\\taller_ds\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-1.1.1 scipy-1.8.1 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.0061 - val_loss: 24.4933\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8189 - val_loss: 0.5414\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4385 - val_loss: 0.4768\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4128 - val_loss: 0.4503\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3955 - val_loss: 0.4673\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5451 - val_loss: 0.4395\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4031 - val_loss: 0.4473\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3943 - val_loss: 0.4177\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3790 - val_loss: 0.4051\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3770 - val_loss: 0.4057\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3684 - val_loss: 0.3973\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3728 - val_loss: 0.4106\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3672 - val_loss: 0.3997\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3575 - val_loss: 0.3947\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3534 - val_loss: 0.3888\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3588 - val_loss: 0.3986\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3517 - val_loss: 0.3912\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3473 - val_loss: 0.3887\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3434 - val_loss: 0.3813\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3436 - val_loss: 0.3883\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "#     [\n",
    "#     keras.layers.Dense(30, activation = 'relu',\n",
    "#                       input_shape = X_train.shape[1:]),\n",
    "    \n",
    "# ])\n",
    "\n",
    "model.add(keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3471\n",
      "0.3471486568450928\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7218366 ],\n",
       "       [2.564496  ],\n",
       "       [3.007024  ],\n",
       "       [1.4103477 ],\n",
       "       [0.81153166]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3521\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3485\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3465\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3451\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3440\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3422A: 0s - los\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3408\n",
      "Epoch 9/30\n",
      "219/363 [=================>............] - ETA: 0s - loss: 0.3336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MIGUEL~1\\AppData\\Local\\Temp/ipykernel_6572/577377571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                    callbacks = [checkpoint_cb])\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m     \"\"\"\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 690\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    691\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 470\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3196 - val_loss: 0.3466\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.3454\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3185 - val_loss: 0.3499\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3597\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3310 - val_loss: 0.3491\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3487\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3239 - val_loss: 0.3462\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('taller_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd1aae4d607d518f7f71ebdb27eeb41d2935ce0eda9928c715d90fa3c042cfaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
